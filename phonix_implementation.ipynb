{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phonix and Soundex Python implementation\n",
    "This is an implementation of the phonix phonetic search algorith [1,2]. This follows the perl[3] and [4] C implementations.\n",
    "\n",
    "Phonix (phonetic indexing) is a technique based on Soundex, but to which\n",
    "'phonetic substitution' has been added as an integral part of both the encoding\n",
    "and the retrieval processes [1]. It is fairly complex, consisting of about 100-160 rules (several rules can be collapsed if they are described using regular expressions. This causes wildly different reports on the number of rules in the litterature)\n",
    "\n",
    "The main jist of the algorithm is that rules based on phonetic spelling are applied to the search and target strings, after which the initial character is saved and all other characters are represented by a numeric value depending on which of 8 groups it belongs to. Finally the 0-group is pruned.\n",
    "\n",
    "Phonix is the same as soundex, only with different groups, a pre-processing step that applies the rules and a seperation of codes into a search key and an ending-sound. If we use the soundex groups and skip the pre-processing and splitting parts, we have soundex. Since this can be achieved in about 3 lines of code, I have decided to include soundex here, even though it is widely available.\n",
    "\n",
    "## Outline of phonix algorithm\n",
    "\n",
    "This algorithm maps a string `name` -> string `phonix code`, consisting of 1 letter followed by several digits. The algorithm assumes all characters in `name` are Alphabetic.\n",
    "\n",
    "a) Perform phonetic substitutions (see Appendix);\n",
    "\t- only the specified characters are dropped, eg. the V or vowel is not \n",
    "      dropped in the substitution of 'N' for 'PN' when 'PNv' is true;\n",
    "\t- the parameters are applied in the specified order;\n",
    "\t- process all occurrences of one substitution before proceeding to the next\n",
    "\t- the result of a substitution may create new target strings for substitution \n",
    "      by subsequent parameters.\n",
    "b) Retain the first character for the retrieval code.\n",
    "\n",
    "c) Replace by 'v' if A, E, I, O, U or Y.\n",
    "\n",
    "d) Where names end in ES, drop the E.\n",
    "\n",
    "e) Append an E where names end in A,I,O,U or Y.\n",
    "\n",
    "f) 0 Drop the last character regardless.\n",
    "\n",
    "g) Drop the new last character if not A,E,I,O,U or Y.\n",
    "\n",
    "h) Repeat g) until a vowel (including Y) is found. This results in a word or name without its ending-sound.\n",
    "\n",
    "i) Strip all occurrences of A,E,I,O,U,Y,H and W.\n",
    "\n",
    "j) Remove one of all duplicate successive consonants.\n",
    "\n",
    "k) Replace ALL consonants by their numeric values.\n",
    "\n",
    "l) Prefix the retrieval code with the retained first character (may be a 'v'[lowercase - see above]).\n",
    "\n",
    "m) Repeat i), j) and k) on the characters removed as stripped ending-sounds\n",
    "\n",
    "---\n",
    "\n",
    "### The PHONIX ending-sound algorithm is:\n",
    "\n",
    "a) If the ending-sound values of an entered name and a retrieved name are the same, the retrieved name is a LIKELY candidate.\n",
    "\n",
    "b) If an entered name has ending-sound value, and the retrieved name does not, then the retrieved name is a LEAST-LIKELY candidate.\n",
    "\n",
    "c) If the two ending-sound values are the same for the length of the shorter, and the difference in length between the two ending-sound values is one digit only, then the retrieved name is a LESS-LIKELY candidate.\n",
    "\n",
    "d) All other cases result in LEAST-LIKELY candidates.\n",
    "\n",
    "## Variations of PHONIX and PHONIX Common\n",
    "\n",
    "According to [5] there are several variants of the Phonix algorithm, such as Phonix4, Phonix8 and PhonixE, which are different in code lengths and components. However, Gong fails to cite these different variations, so it is not possible to implement them.\n",
    "\n",
    "However, looking at examples of phonix keys from the sencondary litterature, it appears that the common interpretation of PHONIX differs from how it was described by Gadd. I have made a second implementation called *PHONIX Common* which matches examples in the secondary litterature by skipping the splitting steps (O-M) and doesn't include the numeric value of the first letter.\n",
    "\n",
    "---\n",
    "\n",
    "(C) Copyright 2015, Mads Olsgaard, http://olsgaard.dk\n",
    "released under [BDS 3](http://opensource.org/licenses/BSD-3-Clause)\n",
    "\n",
    "---\n",
    "\n",
    "1. Gadd, T. N. “‘Fisching Fore Werds’: Phonetic Retrieval of Written Text in Information Systems.” Program 22, no. 3 (1988): 222–37.\n",
    "2. ———. “PHONIX: The Algorithm.” Program 24, no. 4 (1990): 363–66.\n",
    "3. https://github.com/maros/Text-Phonetic/blob/master/lib/Text/Phonetic/Phonix.pm\n",
    "4. soundex.c in [freeWAIS-sf-2.2.10.tar.gz](https://github.com/walkingintopeople/freeWAIS/raw/master/wais/freeWAIS-sf-2.2/freeWAIS-sf-2.2.10.tar.gz)\n",
    "5. Gong, Ruibin, and Tony K. Y. Chan. “Syllable Alignment: A Novel Model for Phonetic String Search.” IEICE TRANSACTIONS on Information and Systems E89-D, no. 1 (January 1, 2006): 332–39.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# init variables and rules\n",
    "\n",
    "vowel = '[AEIOU]';\n",
    "vowely = '[AEIOUY]';\n",
    "consonant = '[BCDFGHJLMNPQRSTVXZXY]';\n",
    "\n",
    "\n",
    "\n",
    "# Define the letter groups\n",
    "\n",
    "                # ABCDEFGHIJKLMNOPQRSTUVWXYZ\n",
    "phonix_digits =  '01230720022455012683070808'\n",
    "soundex_digits = '01230120022455012623010202'\n",
    "\n",
    "\n",
    "\n",
    "# list of transformation/substitution rules\n",
    "#            [pattern, substitution]\n",
    "\n",
    "rules_a = [  [re.compile(r'[^A-Z]'), r''], #Remove all non-alphabet characters. Note that name should be uppercased before applying rules\n",
    "             \n",
    "             [re.compile(r'DG'),    r'G'],\n",
    "             [re.compile(r'C(?=[OAU])'),    r'K'],  # Covers several rules in soundex.c [CO, CA, CU]\n",
    "             [re.compile(r'C[YI]'),    r'SI'],    # Covers [CY, CI]\n",
    "             [re.compile(r'CE'),    r'SE'],\n",
    "             [re.compile(r'^CL(?={})'.format(vowel) ),    r'KL'],\n",
    "             [re.compile(r'CK'),    r'K'],\n",
    "             [re.compile(r'[GJ]C$'),    r'K'],\n",
    "             [re.compile(r'^CH?R(?={})'.format(vowel)),    r'KR'],\n",
    "             [re.compile(r'^WR'),    r'R'],\n",
    "             [re.compile(r'NC'),    r'NK'],\n",
    "             [re.compile(r'CT'),    r'KT'],\n",
    "             [re.compile(r'PH'),    r'F'],\n",
    "             [re.compile(r'AA'),    r'AR'], \n",
    "             [re.compile(r'SCH'),    r'SH'],\n",
    "             [re.compile(r'BTL'),    r'TL'],\n",
    "             [re.compile(r'GHT'),    r'T'],\n",
    "             [re.compile(r'AUGH'),    r'ARF'],\n",
    "             [re.compile(r'(?<={0})LJ(?={0})'.format(vowel)),    r'LD'], #\n",
    "             [re.compile(r'LOUGH'),    r'LOW'],\n",
    "             [re.compile(r'^Q'),    r'KW'],\n",
    "             [re.compile(r'^KN'),    r'N'],\n",
    "             [re.compile(r'GN$'),    r'N'],\n",
    "             [re.compile(r'GHN'),    r'N'],\n",
    "             [re.compile(r'GNE$'),   r'N'],\n",
    "             [re.compile(r'GHNE'),   r'NE'],\n",
    "             [re.compile(r'GNES$'),  r'NS'],\n",
    "             [re.compile(r'^GN'),    r'N'],\n",
    "             [re.compile(r'(?<=\\w)GN(?={})'.format(consonant)),    r'N'],\n",
    "             [re.compile(r'^PS'),    r'S'],\n",
    "             [re.compile(r'^PT'),    r'T'],\n",
    "             [re.compile(r'^CZ'),    r'C'],\n",
    "             [re.compile(r'(?<={})WZ(?=\\w)'.format(vowel)),    r'Z'],\n",
    "             [re.compile(r'(?<=\\w)CZ(?=\\w)'),    r'CH'],\n",
    "             [re.compile(r'LZ'),    r'LSH'],\n",
    "             [re.compile(r'RZ'),    r'RSH'],\n",
    "             [re.compile(r'(?<=\\w)Z(?={})'.format(vowel)),    r'S'],\n",
    "             [re.compile(r'ZZ'),    r'TS'],\n",
    "             [re.compile(r'(?<={})Z(?=\\w)'.format(consonant)),    r'TS'],\n",
    "             [re.compile(r'HROUGH'),    r'[REW]'],\n",
    "             [re.compile(r'OUGH'),    r'OF'],\n",
    "             [re.compile(r'(?<={0})Q(?={0})'.format(vowel)),    r'KW'],\n",
    "             [re.compile(r'(?<={0})J(?={0})'.format(vowel)),    r'Y'],\n",
    "             [re.compile(r'^YJ(?={})'.format(vowel)),    r'Y'],\n",
    "             [re.compile(r'^GH'),    r'G'],\n",
    "             [re.compile(r'(?<={})GH$'.format(vowel)),    r'E'],\n",
    "             [re.compile(r'^CY'),    r'S'],\n",
    "             [re.compile(r'NX'),    r'NKS'],\n",
    "             [re.compile(r'^PF'),    r'F'],\n",
    "             [re.compile(r'DT$'),    r'T'],\n",
    "             [re.compile(r'(?<=[TD])L$'),    r'IL'], # Combines the TL and DL rules\n",
    "             [re.compile(r'YTH'),    r'ITH'],\n",
    "             [re.compile(r'^TS?J(?={})'.format(vowel)),    r'CH'], #combines the TJ and TSJ rules\n",
    "             [re.compile(r'^TS(?={})'.format(vowel)),    r'T'],\n",
    "             [re.compile(r'TCH'),    r'CHE'],\n",
    "             [re.compile(r'(?<={})WSK'.format(vowel)),    r'VSIKE'],\n",
    "             [re.compile(r'^[PM]N(?={})'.format(vowel)),    r'N'],\n",
    "             [re.compile(r'(?<={})STL'.format(vowel)),    r'SL'],\n",
    "             [re.compile(r'TNT$'),    r'ENT'],\n",
    "             [re.compile(r'EAUX$'),    r'OH'],\n",
    "             [re.compile(r'EXCI'),    r'ECS'],\n",
    "             [re.compile(r'X'),    r'ECS'],\n",
    "             [re.compile(r'NED$'),    r'ND'],\n",
    "             [re.compile(r'JR'),    r'DR'],\n",
    "             [re.compile(r'EE$'),    r'EA'],\n",
    "             [re.compile(r'ZS'),    r'S'],\n",
    "             [re.compile(r'(?<={0})H?R(?={1})'.format(vowel, consonant)),    r'AH'], # combines R and HR rule\n",
    "             [re.compile(r'(?<={})HR$'.format(vowel)),    r'AH'], \n",
    "             [re.compile(r'RE$'),    r'AR'],\n",
    "             [re.compile(r'(?<={})R$'.format(vowel)),    r'AH'],\n",
    "             [re.compile(r'LLE'),    r'LE'],\n",
    "             [re.compile(r'(?<={})LE(S?)$'.format(consonant)),    r'ILE\\1'], #combines LE and LES rules\n",
    "             [re.compile(r'E$'),    r''],\n",
    "             [re.compile(r'ES$'),    r'S'],\n",
    "             [re.compile(r'(?<={})SS$'.format(vowel)),    r'AS'],\n",
    "             [re.compile(r'(?<={})MB$'.format(vowel)),    r'M'],\n",
    "             [re.compile(r'MPTS'),    r'MPS'], #Why not just change to MS, if the next rule will do it anyway?\n",
    "             [re.compile(r'MPS'),    r'MS'],\n",
    "             [re.compile(r'MPT'),    r'MT'],\n",
    "        ]\n",
    "\n",
    "rules_de = [ [re.compile(r'ES$'),    r'S'], #STEP D in algorithm.\n",
    "             [re.compile(r'({})$'.format(vowely)),    r'\\1E'], # STEP E in algorithm.\n",
    "                                                               # Appending a vowel is important for splitting name\n",
    "                                                               # into initial and ending-sound\n",
    "            \n",
    "             [re.compile(r'^({}+)$'.format(consonant)), r'\\1E'], # If a name has no vowels, STEP F and G will fail in code\n",
    "                                                                # Adding a dummy vowel ensures there will be a final\n",
    "           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#functions\n",
    "\n",
    "def _encode(name, digits, len=4):\n",
    "    # The encoding step of phonix is the same as the encoding step of\n",
    "    # soundex, except other codes are used.\n",
    "    \n",
    "    # name should be uppercased before calling this function!\n",
    "\n",
    "    key = ''\n",
    "\n",
    "    # translate alpha chars in name to soundex digits\n",
    "        \n",
    "    ord_A = 65 #No need to call ord everytime\n",
    "    \n",
    "    for c in name:\n",
    "        if c.isalpha():\n",
    "            d = digits[ord(c)-ord_A]\n",
    "            \n",
    "            # duplicate consecutive soundex digits are skipped\n",
    "            if not key or (d != key[-1]):\n",
    "                key += d\n",
    "\n",
    "    # remove all 0s from the soundex code\n",
    "    key = key.replace('0','')\n",
    "\n",
    "    return key\n",
    "\n",
    "\n",
    "def soundex(name):\n",
    "    key = _encode(name.upper(), soundex_digits)\n",
    "    return (name[0].upper()+key[1:]+'000')[:4]\n",
    "\n",
    "def apply_rules(name, rules):\n",
    "    for rule in rules_a:\n",
    "        name = rule[0].sub(rule[1], name)    \n",
    "    return name\n",
    "\n",
    "def phonix(name, verbose = False):\n",
    "    ''' Takes a string `name` and generates a phonix phonetic key.\n",
    "    The key is a touple consisting of the retrieval code and ending-sound\n",
    "    as described in \"The Phonix Algorithm\", 1990, doi: 10.1108/eb047069\n",
    "    \n",
    "    input:      string that needs to be converted to a key\n",
    "    Returns:    a touple key consisting of a retrieval code and ending-sound \n",
    "    \n",
    "    if `verbose` == true, the function also returns the name after the phonetic\n",
    "    substitution rules described in step A the paper.'''\n",
    "    \n",
    "    name = name.upper()\n",
    "    \n",
    "    #Apply all phonetic substitution rules sequentially, STEP A\n",
    "    name = apply_rules(name, rules_a) \n",
    "    \n",
    "    #retain rule. STEP B and C\n",
    "    first_char = name[0] if name[0] not in vowely else 'v' \n",
    "    \n",
    "    #Apply substitution rule from STEP D and E\n",
    "    name = apply_rules(name, rules_de)\n",
    "    \n",
    "    # Extract and remove ending-sound, STEP F and G\n",
    "    # Gadd uses ending-sound instead of final, and doesn't give the initial \n",
    "    # part of the name a nomenclature.\n",
    "    \n",
    "    for i in range(1, len(name)):\n",
    "        if name[-(i+1)] in vowely:\n",
    "            initial, final = name[:-i], name[-i:]\n",
    "            break\n",
    "            \n",
    "    else:   # If we never hit the break statement. This happens if len(name) <= 2 \n",
    "            # or consist of any number of consonants ending with a vowel, like fffffu\n",
    "            # It is unclear from Gadd how such edge-cases should be handled. I assume the\n",
    "            # entire name, since G is described as being recursive.\n",
    "        \n",
    "        initial, final = \"E\", name  # The 'E' is a dummy vowel, that will dissappear once \n",
    "                                    # `initial` is encoded. The entire name will be stored in\n",
    "                                    # `final`. Retrieval code will thus become the initial letter. \n",
    "                                    # That is \"Fu\" -> ('F', '7')\n",
    "        \n",
    "    key = (first_char+_encode(initial, phonix_digits), _encode(final, phonix_digits) ) #Apply STEP I, J and K\n",
    "    if verbose:\n",
    "        return name, key\n",
    "    \n",
    "    return key\n",
    "\n",
    "def phonix_common(name, verbose=False, length=4):\n",
    "    ''' similar to Phonix function, only it generates results similar to what is\n",
    "    found in the secondary litterature about the Phonix algorithm, such as Christensen 2012\n",
    "    and the freeWAIS-sf implementation.\n",
    "    This algorithm does the phonetic substitution following STEP A, but then generates the key\n",
    "    in a similar fashion to soundex, only using the phonix mappings. This means that no \n",
    "    retrieval code and ending-sound code are generated, instead the key consist of only 1 code.\n",
    "    Moreover, the numerical value for the first letter is not stored in the key at all,\n",
    "    but first letter vowels are converted to 'v', however. '''\n",
    "    \n",
    "    name = name.upper()\n",
    "    \n",
    "    #Apply all phonetic substitution rules sequentially, STEP A\n",
    "    name = apply_rules(name, rules_a)\n",
    "    \n",
    "    first_char = name[0] if name[0] not in vowely else 'v' \n",
    "    \n",
    "    key = _encode(name.upper(), phonix_digits)\n",
    "    \n",
    "    key = (first_char+key[1:]+'0'*length)[:length] \n",
    "    \n",
    "    if verbose:\n",
    "        return name, key\n",
    "    \n",
    "    return key\n",
    "\n",
    "def phonix_search_key(search_key, key_corpus):\n",
    "    ''' Search for a key in a corpus of names. `key_corpus` should\n",
    "    be an iterable of keys generated by the `phonix()` function.\n",
    "    Return likely, less-likely and least-likely candidates according to\n",
    "    the phonix search algorithm (or phonix ending-sound algorithm) as described \n",
    "    in \"The Phonix Algorithm\", 1990, doi: 10.1108/eb047069\n",
    "    \n",
    "    input:       search_key: a single key generated by the `phonix()` function\n",
    "                 corpus_key: a list of keys generated by the `phonix()` function.\n",
    "    \n",
    "    returns:     3 lists of integers. Integers represent index keys to the key_corpus variable\n",
    "                 likely, less_likely, least_likely '''\n",
    "    \n",
    "    likely, less_likely, least_likely = [],[],[]\n",
    "    \n",
    "    initial, final = search_key\n",
    "    \n",
    "    for i, (ini, fin) in enumerate(key_corpus):\n",
    "        if initial == ini:\n",
    "            \n",
    "            # STEP A\n",
    "            if fin == final:\n",
    "                likely.append(i)\n",
    "                continue # ignore remaining code and continue the for-loop \n",
    "            # STEP B            \n",
    "            if len(final) > 1 and len(fin) ==0:\n",
    "                least_likely.append(i)\n",
    "                continue\n",
    "            # STEP C            \n",
    "            shortest = max(len(fin), len(final))\n",
    "            if fin[:shortest] == final[:shortest] and abs(len(fin)-len(final)) == 1:\n",
    "                less_likely.append(i)\n",
    "                continue\n",
    "            #STEP D\n",
    "            least_likely.append(i)\n",
    "            \n",
    "    return likely, less_likely, least_likely  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing code generation and retrieval\n",
    "Let's do some sanity tests. Names and codes listed under the column \"Christensen\" are taken from \"Data-centric systems and applications\" By Peteer Christensen, Springer 2012\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name          sndx code     Christensen   phonix        phonix code   Christensen   phonix_common \n",
      "--------------------------------------------------------------------------------------------------\n",
      "peter         P360          p360          PETEAH        P13,          p300          P300          \n",
      "pete          P300          p300          PET           P1,3          p300          P300          \n",
      "pedro         P360          p360          PEDRO         P1,36         p360          P360          \n",
      "stephen       S315          s315          STEFEN        S837,5        s375          S375          \n",
      "steve         S310          s310          STEV          S83,7         s370          S370          \n",
      "smith         S530          s530          SMITH         S85,3         s530          S530          \n",
      "smythe        S530          s530          SMITH         S85,3         s530          S530          \n",
      "gail          G400          g400          GAIL          G2,4          g400          G400          \n",
      "gayle         G400          g400          GAYIL         G2,4          g400          G400          \n",
      "christine     C623          c623          KRISTIN       K2683,5       c683          K683          \n",
      "christina     C623          c623          KRISTINA      K2683,5       c683          K683          \n",
      "kristina      K623          k623          KRISTINA      K2683,5       k683          K683          \n"
     ]
    }
   ],
   "source": [
    "columns = '{:14}'*7\n",
    "hr = \"-\"*7*14\n",
    "\n",
    "test_names = ['peter', 'pete', 'pedro', 'stephen', 'steve', 'smith', 'smythe', 'gail', 'gayle', 'christine', \n",
    "              'christina', 'kristina']\n",
    "soundex_codes = ['p360', 'p300', 'p360', 's315', 's310', 's530', 's530', 'g400', 'g400', 'c623', 'c623', \n",
    "                 'k623']\n",
    "phonix_codes = ['p300', 'p300', 'p360', 's375', 's370', 's530', 's530', 'g400', 'g400', 'c683', 'c683', \n",
    "                'k683']\n",
    "\n",
    "print( columns.format('Name', \"sndx code\", 'Christensen', 'phonix', 'phonix code', 'Christensen', \n",
    "                     'phonix_common') )\n",
    "print( hr )\n",
    "for i, n in enumerate(test_names):\n",
    "    p = phonix(n, verbose=True)\n",
    "    print( columns.format(n, soundex(n), soundex_codes[i], p[0], ','.join(p[1]), phonix_codes[i], \n",
    "                         phonix_common(n)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the way Christensen generates Phonix codes in his book \"Data-centric systems and applications\", 2012 differs greatly from how Gadd describes them in his papers.\n",
    "\n",
    "---\n",
    "\n",
    "### Comparison to codes in original paper\n",
    "Now let's test against codes published by Gadd himself in \"Fisching fore werds\", 1988. Gadd doesn't publish any examples split into retrieval code and ending-sound, but if we collapse the touples, we see that this algorithm matches the one outlined by Gadd. *Soundex* and *Phonix* codes generated by this implementation is listed as \"*phonix code*\", and codes listed in the original paper are listed under the columns \"*true*\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name, \t soundex_code, \ttrue, \tphonix,\t phonix code,\ttrue\n",
      "\n",
      "Knight    \tK523\tK523\tNIT\t\tN5,3\tN53\n",
      "Night    \tN230\tN230\tNIT\t\tN5,3\tN53\n",
      "Nite    \tN300\tN300\tNIT\t\tN5,3\tN53\n",
      "Write    \tW300\tW630\tRIT\t\tR6,3\tR63\n",
      "Wright    \tW230\tW623\tRIT\t\tR6,3\tR63\n",
      "Rite    \tR300\tR300\tRIT\t\tR6,3\tR63\n",
      "White    \tW000\tW300\tWHIT\t\tW,3\tW3\n",
      "Weight    \tW300\tW230\tWEIT\t\tW,3\tW3\n",
      "Yaeger    \tY600\tY230\tYAEGEAH\t\tv2,\tv2\n",
      "Yoga    \tY000\tY800\tYOGA\t\tv,2\tv2\n",
      "Eager    \tE600\tE230\tEAGEAH\t\tv2,\tv2\n",
      "Auger    \tA600\tA230\tAUGEAH\t\tv2,\tv2\n"
     ]
    }
   ],
   "source": [
    "test_names = ['Knight', 'Night', 'Nite', 'Write', 'Wright', 'Rite', 'White', 'Weight', \n",
    "              'Yaeger', 'Yoga', 'Eager', 'Auger']\n",
    "soundex_codes = ['K523', 'N230', 'N300', 'W630', 'W623', 'R300', 'W300', 'W230',\n",
    "                 'Y230', 'Y800', 'E230', 'A230']\n",
    "phonix_codes = ['N53','N53','N53', 'R63', 'R63', 'R63', 'W3','W3',\n",
    "                'v2', 'v2', 'v2', 'v2']\n",
    "\n",
    "print( 'Name, \\t soundex_code, \\ttrue, \\tphonix,\\t phonix code,\\ttrue\\n' )\n",
    "for i, n in enumerate(test_names):\n",
    "    p = phonix(n, verbose=True)\n",
    "    print( '\\t'.join([n+'    ', soundex(n), soundex_codes[i], p[0]+'\\t', ','.join(p[1]), phonix_codes[i]]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval\n",
    "Let's do some retrieval! Here we load about 155.947 names collected from the 1990 US census, and do some retrievals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15 s, sys: 11.9 ms, total: 15 s\n",
      "Wall time: 15 s\n"
     ]
    }
   ],
   "source": [
    "#Load names\n",
    "corpus = open(\"names.csv\", \"r\").read().split(',')\n",
    "\n",
    "#Generate index of keys. Shouldn't take more than 20 seconds.\n",
    "%time key_corpus =[phonix(name) for name in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "term = \"knight\"\n",
    "key = phonix(term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "likely, less_likely, least_likely = phonix_search_key(key, key_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing the first  likely 10 results from names.csv that match knight\n",
      "----------------------------------------------------\n",
      "Search term  Result term  phonix phono phonix key   \n",
      "----------------------------------------------------\n",
      "knight         NOTT       nott         N5,3         \n",
      "knight         NOTE       not          N5,3         \n",
      "knight         NOTO       noto         N5,3         \n",
      "knight         NOTH       noth         N5,3         \n",
      "knight         KNODE      nod          N5,3         \n",
      "knight         NOORDA     nooahda      N5,3         \n",
      "knight         NARD       naahhd       N5,3         \n",
      "knight         NOOD       nood         N5,3         \n",
      "knight         KNUTTI     nutti        N5,3         \n",
      "knight         NIETTE     niett        N5,3         \n",
      "\n",
      " ----------------------------------------------------\n",
      "Number of:   Likely       Less-likely  Least-likely \n",
      "             138          0            959          \n"
     ]
    }
   ],
   "source": [
    "columns = '{:<13}'*4\n",
    "hr = \"-\"*4*13\n",
    "\n",
    "print( \"Showing the first  likely 10 results from names.csv that match\", term )\n",
    "print( hr )\n",
    "print( columns.format(\"Search term\", \"Result term\", \"phonix phono\", \"phonix key\") )\n",
    "print( hr )\n",
    "for l in likely[:10]:\n",
    "    k = phonix(corpus[l], verbose=True)\n",
    "    print( columns.format(term, corpus[l], k[0].lower(), ','.join(k[1])) )\n",
    "\n",
    "print( '\\n', hr)\n",
    "print( columns.format(\"Number of:\", \"Likely\", \"Less-likely\", \"Least-likely\") )\n",
    "print( columns.format('', len(likely), len(less_likely), len(least_likely)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
